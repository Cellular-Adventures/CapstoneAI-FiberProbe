{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ca701-cbf0-4be8-828c-842a65f9fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start user input ###\n",
    "path_to_data = []\n",
    "path_to_output = \n",
    "### End user input ###\n",
    "\n",
    "# Libary imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Function imports\n",
    "from advanced_dataloading import process_folder\n",
    "from advanced_preprocessing import frame_waves, valid_velo_data\n",
    "from models import load_scalers, LSTMModel, GRUModel\n",
    "\n",
    "gru1 = GRUModel(input_size=1, hidden_size=20, num_layers=2)\n",
    "gru1.load_state_dict(torch.load(r'path_to_your_model\\your_model_weights.h5', map_location='cpu'))\n",
    "gru1.eval()\n",
    "\n",
    "gru2 = GRUModel(input_size=1, hidden_size=25, num_layers=2)\n",
    "gru2.load_state_dict(torch.load(r'path_to_your_model\\your_model_weights.h5', map_location='cpu'))\n",
    "gru2.eval()\n",
    "\n",
    "lstm = LSTMModel(input_size=1, hidden_size=25, num_layers=2)\n",
    "lstm.load_state_dict(torch.load(r'path_to_your_model\\your_model_weights.h5', map_location='cpu'))\n",
    "lstm.eval()\n",
    "\n",
    "feature_scaler, target_scaler, feature_scaler2 = load_scalers()\n",
    "\n",
    "df = process_folder()\n",
    "X_array = np.vstack(df[\"VoltageOut\"].to_numpy())  # shape: (samples, timesteps)\n",
    "X_scaled = feature_scaler.transform(X_array)      # apply your trained scaler\n",
    "X_tensor = torch.tensor(X_scaled[..., np.newaxis], dtype=torch.float32)  # shape: (samples, timesteps, 1)\n",
    "\n",
    "with torch.no_grad():  \n",
    "        y_gru1_scaled = gru1(X_tensor)\n",
    "        y_gru2_scaled = gru2(X_tensor)\n",
    "        y_lstm_scaled = lstm(X_tensor)\n",
    "y_gru1 = target_scaler.inverse_transform(y_gru1_scaled.detach().cpu().numpy().reshape(-1, 1)).flatten()\n",
    "y_gru2 = target_scaler.inverse_transform(y_gru2_scaled.detach().cpu().numpy().reshape(-1, 1)).flatten()\n",
    "y_lstm = target_scaler.inverse_transform(y_lstm_scaled.detach().cpu().numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "y_pred = ((y_lstm+y_gru1+y_gru2)/3).flatten()\n",
    "outcome_df = pd.DataFrame({\"predictions model 1\": y_gru1, \"predictions model 2\": y_gru2, \"predictions model 3\": y_lstm, \"final prediction\": y_pred})\n",
    "outcome_df['Standard deviation'] = outcome_df[[\"predictions model 1\", \"predictions model 2\", \"predictions model 3\"]].std(axis=1)\n",
    "outcome_df['Standard deviation %'] = outcome_df['Standard deviation'] / outcome_df['final prediction'] * 100\n",
    "\n",
    "print(outcome_df.head(10))\n",
    "\n",
    "# Evaluation metrics (remove '''...''' if interested)\n",
    "valid_bubbles_ai = len(outcome_df[outcome_df['Standard deviation %'] < 10])/len(outcome_df) * 100\n",
    "valid_bubbles_boring_software = len(valid_velo_data(df)[0])/len(df) * 100\n",
    "\n",
    "X_velo, y_velo = valid_velo_data(df)\n",
    "X_velo = frame_waves(X_velo, length=150, jump=0)[0]\n",
    "X_velo_scaled = torch.tensor(feature_scaler.transform(X_velo)[...,np.newaxis], dtype=torch.float32)\n",
    "with torch.no_grad():  \n",
    "        y_gru1_scaled_velo = gru1(X_velo_scaled)\n",
    "        y_gru2_scaled_velo = gru2(X_velo_scaled)\n",
    "        y_lstm_scaled_velo = lstm(X_velo_scaled)\n",
    "y_gru1_velo = target_scaler.inverse_transform(y_gru1_scaled_velo.detach().cpu().numpy().reshape(-1, 1)).flatten()\n",
    "y_gru2_velo = target_scaler.inverse_transform(y_gru2_scaled_velo.detach().cpu().numpy().reshape(-1, 1)).flatten()\n",
    "y_lstm_velo = target_scaler.inverse_transform(y_lstm_scaled_velo.detach().cpu().numpy().reshape(-1, 1)).flatten()\n",
    "y_pred_velo = ((y_lstm_velo+y_gru1_velo+y_gru2_velo)/3).flatten()\n",
    "outcome_df_valid = pd.DataFrame({\"predictions model 1\": y_gru1_velo, \"predictions model 2\": y_gru2_velo, \"predictions model 3\": y_lstm_velo, \"final prediction\": y_pred_velo})\n",
    "outcome_df_valid['Standard deviation'] = outcome_df_valid[[\"predictions model 1\", \"predictions model 2\", \"predictions model 3\"]].std(axis=1)\n",
    "outcome_df_valid['Standard deviation %'] = outcome_df_valid['Standard deviation'] / outcome_df_valid['final prediction'] * 100\n",
    "valid_test_results = outcome_df_valid[(outcome_df_valid[\"Standard deviation\"]/outcome_df_valid[\"final prediction\"]) <= 0.1]\n",
    "\n",
    "filtered_outcome_df = outcome_df[outcome_df['Standard deviation %'] < 10]\n",
    "average_percentage_std = filtered_outcome_df['Standard deviation %'].mean()\n",
    "\n",
    "print(f\"Percentage found valid bubbles (uncertainty < 10%) with speed difference <10% from truth:  {len(valid_test_results) / (len(outcome_df_valid)) * 100:.4f} %\")\n",
    "print(f'Percentage AI found valid bubbles (uncertainty < 10%): {valid_bubbles_ai:.4f} % vs M2 analyzer: {valid_bubbles_boring_software:.4f} %, improvement: {((valid_bubbles_ai - valid_bubbles_boring_software)/valid_bubbles_boring_software)*100:.4f} %')\n",
    "print(f'Model uncertainty (average uncertainty of valid bubbles): {average_percentage_std:.4f} % with {len(filtered_outcome_df) / len(outcome_df_valid) * 100} % of the labled samples')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
